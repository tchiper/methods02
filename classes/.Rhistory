#replace English bilingualism
df <- df %>%
mutate(bilingualism = ifelse(bilingualism %in% c("English", "Engish"), "none", bilingualism))
#create a new column with condition(congruent or incongruent)
df <- df %>%
mutate(overall_cond = ifelse(condition == 1, "congruent", "incongruent"))
#build a new column with correctness
df <- df %>%
mutate(correctness = ifelse(answer == right_ans, "correct", "incorrect"))
#Convert 'Condition' and 'ID' to factor data type
df$condition <- as.factor(df$condition)
df$id <- as.factor(df$id)
df$gender <- as.factor(df$gender)
df$overall_cond <- as.factor(df$overall_cond)
df$correctness <- as.factor(df$correctness)
df$use_of_english <- as.numeric(df$use_of_english)
df$native_language <- as.character(df$native_language)
#result_table <- df %>%
# group_by(condition) %>%
# summarize(across(c(age, age_english, use_of_english), list(mean = mean, sd = sd), na.rm = TRUE))
#print(result_table)
# Save the result_table to a CSV file
#write.csv(result_table, "C:/Users/chipe/Downloads/cogcom/table_data.csv", row.names = FALSE)
#remove the outliers
sd_3 <- 3*sd(df$reaction_time)
#identifying influential cases bigger or smaller than 3SD
outlier_upper <- which(df$reaction_time > mean(df$reaction_time) + sd_3, arr.ind = TRUE)
outlier_lower <- which(df$reaction_time < mean(df$reaction_time) - sd_3, arr.ind = TRUE)
outliers <- c(outlier_upper, outlier_lower)
# Remove outliers from the data
df_no_outliers <- df[-outliers, ]
mymodel <- lmer(reaction_time ~ overall_cond + (1|id) + (1|q_n), data=df_no_outliers, REML=FALSE)
#1. Linearity of residuals
plot(fitted(mymodel),residuals(mymodel))
#after visually assesing the data points, there are some violations of linearity.
#2. Absence of colinearity
#we only have one predictor in our experimental design
#3. Homoskedasticty - need to transform data
plot(mymodel)
#the data points do not have the same variance
#4. Normality of residuals
qqnorm(residuals(mymodel))
hist(residuals(mymodel))
#the data show skewness
#5 independence - we accounted for each subject
#we will transform the data using log transformation and check again
mylogmodel <- lmer(log(reaction_time) ~ overall_cond + (1|id) + (1|q_n), data=df_no_outliers, REML=FALSE)
#1. Linearity of residuals
plot(fitted(mylogmodel),residuals(mylogmodel))
#it seems to meet the linearity assumption
#2. Homoskedasticty - need to transform data
plot(mylogmodel)
#the data points seem to have the same variance
#4. Normality of residuals
qqnorm(residuals(mylogmodel))
hist(residuals(mylogmodel))
#the residuals seem to be normally distributed (numerically confirmed with Shapiro-Wilk's test)
shapiro.test(residuals(mylogmodel))
#we will use mylogmodel
summary(mylogmodel)
#creating a null model
nullmodel <-  lmer(log(reaction_time) ~ 1 + (1|id) + (1|q_n), data=df_no_outliers,
REML=FALSE)
#compare them
anova(mylogmodel, nullmodel)
#the p-values are the same for mylogmodel and the anova test
#plotting
df_no_outliers %>%
ggplot(aes(x = overall_cond, y = reaction_time, colour = overall_cond)) +
geom_boxplot() +
ggtitle("Reaction time by overall condition") +
labs(x = "Overall condition", y = "Reaction time (s)") +
theme_minimal()
#create a new column with the accuracy
df <- df %>%
group_by(id) %>%
mutate(accuracy = sum(correctness == "correct")/n())
#create a new data frame with id, condition and accuracy
accuracy_df <- data.frame(overall_cond = df$overall_cond, id = df$id, accuracy = df$accuracy, use_of_english = df$use_of_english)
#keep only row for each participant
accuracy_df <- accuracy_df[!duplicated(accuracy_df) & !duplicated(accuracy_df, fromLast = F), ]
accuracy_df$overall_cond <- as.factor(accuracy_df$overall_cond)
#mean(accuracy_df$accuracy)
#sd(accuracy_df$accuracy)
# Calculate the threshold for identifying outliers
sd_3_acc <- 3 * sd(accuracy_df$accuracy)
# Identify upper and lower outliers
outlier_upper_acc <- which(accuracy_df$accuracy > mean(accuracy_df$accuracy) + sd_3_acc)
outlier_lower_acc <- which(accuracy_df$accuracy < mean(accuracy_df$accuracy) - sd_3_acc)
# Combine the indices of outliers
outliers_acc <- c(outlier_upper_acc, outlier_lower_acc)
outliers_acc
#there are no outliers
#build a linear model to predict accuracy by overall condition
model2 <- lm(accuracy ~ overall_cond, data = accuracy_df)
#test for assumptions
#1. Linearity of residuals
plot(model2)
#2. Absence of colinearity
#we only have one predictor in our experimental design
#3. Homoskedasticty
leveneTest(accuracy ~ overall_cond, data = accuracy_df)
#it suggests homoskedasticity
#4. Normality of residuals
qqnorm(residuals(model2))
hist(residuals(model2))
shapiro.test(residuals(model2))
#it suggests normality of residuals
#5 independence - one value per subject
summary(model2)
#signifcant p-value and adjusted-r squared
#plotting
accuracy_df %>%
ggplot(aes(x = overall_cond, y = accuracy, colour = overall_cond)) +
geom_boxplot() +
ggtitle("Accuracy by condition") +
labs(x = "Overall condition", y = "Accuracy") +
theme_minimal()
linmodel <- lm(accuracy ~ use_of_english, data = accuracy_df)
summary(linmodel)
plot(accuracy ~ use_of_english, data = accuracy_df, main = "Scatter Plot with Regression Line")
abline(linmodel, col = "red")
intermodel <- lm(accuracy ~ use_of_english*overall_cond, data = accuracy_df)
#1. Linearity of residuals
plot(intermodel)
#2. Absence of colinearity
vif(intermodel)
#3. Homoskedasticty
#it suggests homoskedasticity
#4. Normality of residuals
qqnorm(residuals(intermodel))
hist(residuals(intermodel))
shapiro.test(residuals(intermodel))
#it suggests normality of residuals
#5 independence - one value per subject
ggplot(accuracy_df, aes(x = use_of_english,
y = accuracy,
col = overall_cond))+
geom_point() +
geom_smooth(method = "lm", se = FALSE)
summary(intermodel)
emmeans(intermodel, pairwise ~ overall_cond, var = "accuracy", data = accuracy_df)
View(df)
View(accuracy_df)
result_table <- df %>%
group_by(native_language) %>%
summarize(across(c(age, age_english, use_of_english), list(mean = mean, sd = sd), na.rm = TRUE))
print(result_table)
# Save the result_table to a CSV file
#write.csv(result_table, "C:/Users/chipe/Downloads/cogcom/table_data.csv", row.names = FALSE)
result_table <- df %>%
group_by(native_language) %>%
summarize(across(c(age, age_english, use_of_english), list(mean = mean, sd = sd), na.rm = TRUE))
print(result_table)
# Save the result_table to a CSV file
write.csv(result_table, "C:/Users/chipe/Downloads/cogcom/table_data.csv", row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readr)
library(ggplot2)
library(dplyr)
library(lmerTest)
library(lme4)
library(broom)
library(ggfortify)
library(car)
library(emmeans)
library(findpython)
#code for anonymization from class 6 (i think)
path0 <- file.path("C:/Users/chipe/Downloads/cogcom/logfiles") #folder where the files are
new_path <- file.path("C:/Users/chipe/Downloads/cogcom/anonlogfiles") #new folder for anonymized data
if (!dir.exists(new_path)) {
dir.create(new_path)
}
if (length(list.files(path = new_path,
pattern = "*logfile_snew*",
full.names = TRUE)) == 0) {
files <- list.files(path = path0, pattern = "*logfile_*", full.names = TRUE)
num_files <- length(files)
rand_ids <- sample(num_files)
for (f in seq_along(files)) {
data <- read.csv(files[f], header = TRUE)
data$id <- paste0("snew", rand_ids[f])
out_name <- file.path(new_path, paste0("logfile_", data$id[1], ".csv"))
write.csv(data, out_name, na = "NA", row.names = FALSE)
}
}
#filepath for the anonymized folder
filepath <- "C:/Users/chipe/Downloads/cogcom/anonlogfiles"
files <- list.files(path = filepath, pattern = "*.csv", full.names = TRUE)
df <- readr::read_csv(files, id = "file_name")
#clean the data
#remove the file_name column
df$file_name <- NULL
#rename column names
df <- df %>%
rename(age_english = how_long,
use_of_english = how_much)
#create a new column with the native language
df$native_language <- df$parents_nat_language
#replace English bilingualism
df <- df %>%
mutate(bilingualism = ifelse(bilingualism %in% c("English", "Engish"), "none", bilingualism))
#create a new column with condition(congruent or incongruent)
df <- df %>%
mutate(overall_cond = ifelse(condition == 1, "congruent", "incongruent"))
#build a new column with correctness
df <- df %>%
mutate(correctness = ifelse(answer == right_ans, "correct", "incorrect"))
#Convert 'Condition' and 'ID' to factor data type
df$condition <- as.factor(df$condition)
df$id <- as.factor(df$id)
df$gender <- as.factor(df$gender)
df$overall_cond <- as.factor(df$overall_cond)
df$correctness <- as.factor(df$correctness)
df$use_of_english <- as.numeric(df$use_of_english)
df$native_language <- as.character(df$native_language)
result_table <- df %>%
group_by(native_language) %>%
summarize(across(c(age, age_english, use_of_english), list(mean = mean, sd = sd), na.rm = TRUE))
print(result_table)
# Save the result_table to a CSV file
#write.csv(result_table, "C:/Users/chipe/Downloads/cogcom/table_data.csv", row.names = FALSE)
#remove the outliers
sd_3 <- 3*sd(df$reaction_time)
#identifying influential cases bigger or smaller than 3SD
outlier_upper <- which(df$reaction_time > mean(df$reaction_time) + sd_3, arr.ind = TRUE)
outlier_lower <- which(df$reaction_time < mean(df$reaction_time) - sd_3, arr.ind = TRUE)
outliers <- c(outlier_upper, outlier_lower)
# Remove outliers from the data
df_no_outliers <- df[-outliers, ]
mymodel <- lmer(reaction_time ~ overall_cond + (1|id) + (1|q_n), data=df_no_outliers, REML=FALSE)
#1. Linearity of residuals
plot(fitted(mymodel),residuals(mymodel))
#after visually assesing the data points, there are some violations of linearity.
#2. Absence of colinearity
#we only have one predictor in our experimental design
#3. Homoskedasticty - need to transform data
plot(mymodel)
#the data points do not have the same variance
#4. Normality of residuals
qqnorm(residuals(mymodel))
hist(residuals(mymodel))
#the data show skewness
#5 independence - we accounted for each subject
#we will transform the data using log transformation and check again
mylogmodel <- lmer(log(reaction_time) ~ overall_cond + (1|id) + (1|q_n), data=df_no_outliers, REML=FALSE)
#1. Linearity of residuals
plot(fitted(mylogmodel),residuals(mylogmodel))
#it seems to meet the linearity assumption
#2. Homoskedasticty - need to transform data
plot(mylogmodel)
#the data points seem to have the same variance
#4. Normality of residuals
qqnorm(residuals(mylogmodel))
hist(residuals(mylogmodel))
#the residuals seem to be normally distributed (numerically confirmed with Shapiro-Wilk's test)
shapiro.test(residuals(mylogmodel))
#we will use mylogmodel
summary(mylogmodel)
#creating a null model
nullmodel <-  lmer(log(reaction_time) ~ 1 + (1|id) + (1|q_n), data=df_no_outliers,
REML=FALSE)
#compare them
anova(mylogmodel, nullmodel)
#the p-values are the same for mylogmodel and the anova test
#plotting
df_no_outliers %>%
ggplot(aes(x = overall_cond, y = reaction_time, colour = overall_cond)) +
geom_boxplot() +
ggtitle("Reaction time by overall condition") +
labs(x = "Overall condition", y = "Reaction time (s)") +
theme_minimal()
#create a new column with the accuracy
df <- df %>%
group_by(id) %>%
mutate(accuracy = sum(correctness == "correct")/n())
#create a new data frame with id, condition and accuracy
accuracy_df <- data.frame(overall_cond = df$overall_cond, id = df$id, accuracy = df$accuracy, use_of_english = df$use_of_english, age_english = df$age_english)
#keep only row for each participant
accuracy_df <- accuracy_df[!duplicated(accuracy_df) & !duplicated(accuracy_df, fromLast = F), ]
accuracy_df$overall_cond <- as.factor(accuracy_df$overall_cond)
#mean(accuracy_df$accuracy)
#sd(accuracy_df$accuracy)
# Calculate the threshold for identifying outliers
sd_3_acc <- 3 * sd(accuracy_df$accuracy)
# Identify upper and lower outliers
outlier_upper_acc <- which(accuracy_df$accuracy > mean(accuracy_df$accuracy) + sd_3_acc)
outlier_lower_acc <- which(accuracy_df$accuracy < mean(accuracy_df$accuracy) - sd_3_acc)
# Combine the indices of outliers
outliers_acc <- c(outlier_upper_acc, outlier_lower_acc)
outliers_acc
#there are no outliers
#build a linear model to predict accuracy by overall condition
model2 <- lm(accuracy ~ overall_cond, data = accuracy_df)
#test for assumptions
#1. Linearity of residuals
plot(model2)
#2. Absence of colinearity
#we only have one predictor in our experimental design
#3. Homoskedasticty
leveneTest(accuracy ~ overall_cond, data = accuracy_df)
#it suggests homoskedasticity
#4. Normality of residuals
qqnorm(residuals(model2))
hist(residuals(model2))
shapiro.test(residuals(model2))
#it suggests normality of residuals
#5 independence - one value per subject
summary(model2)
#signifcant p-value and adjusted-r squared
#plotting
accuracy_df %>%
ggplot(aes(x = overall_cond, y = accuracy, colour = overall_cond)) +
geom_boxplot() +
ggtitle("Accuracy by condition") +
labs(x = "Overall condition", y = "Accuracy") +
theme_minimal()
linmodel <- lm(accuracy ~ use_of_english, data = accuracy_df)
summary(linmodel)
plot(accuracy ~ use_of_english, data = accuracy_df, main = "Scatter Plot with Regression Line")
abline(linmodel, col = "red")
intermodel <- lm(accuracy ~ use_of_english*overall_cond, data = accuracy_df)
#1. Linearity of residuals
plot(intermodel)
#2. Absence of colinearity
vif(intermodel)
#3. Homoskedasticty
#it suggests homoskedasticity
#4. Normality of residuals
qqnorm(residuals(intermodel))
hist(residuals(intermodel))
shapiro.test(residuals(intermodel))
#it suggests normality of residuals
#5 independence - one value per subject
ggplot(accuracy_df, aes(x = use_of_english,
y = accuracy,
col = overall_cond))+
geom_point() +
geom_smooth(method = "lm", se = FALSE)
summary(intermodel)
emmeans(intermodel, pairwise ~ overall_cond, var = "accuracy", data = accuracy_df)
othermodel <- lm(accuracy ~ age_english*overall_cond, data = accuracy_df)
summary(othermodel)
ggplot(accuracy_df, aes(x = age_english,
y = accuracy,
col = overall_cond))+
geom_point() +
geom_smooth(method = "lm", se = FALSE)
View(df)
View(accuracy_df)
ggplot(accuracy_df, aes(x = age_english,
y = accuracy,
col = overall_cond))+
geom_point() +
geom_smooth(method = "lm", se = FALSE)
#we will use mylogmodel
summary(mylogmodel)
#creating a null model
#nullmodel <-  lmer(log(reaction_time) ~ 1 + (1|id) + (1|q_n), data=df_no_outliers,
REML=FALSE)
#we will use mylogmodel
summary(mylogmodel)
#creating a null model
#nullmodel <-  lmer(log(reaction_time) ~ 1 + (1|id) + (1|q_n), data=df_no_outliers,
# REML=FALSE)
#compare them
#anova(mylogmodel, nullmodel)
#the p-values are the same for mylogmodel and the anova test
#creating a null model
#nullmodel <-  lmer(log(reaction_time) ~ 1 + (1|id) + (1|q_n), data=df_no_outliers,
# REML=FALSE)
#compare them
anova(mylogmodel, nullmodel)
ggplot(accuracy_df, aes(x = use_of_english,
y = accuracy,
col = overall_cond))+
geom_point() +
geom_smooth(method = "lm", se = FALSE)
modelnou <- lm(accuracy ~ use_of_english + overall_cond, data = accuracy_df)
summary(modelnou)
anova(intermodel, modelnou)
model2
anova(modelnou, model2)
anova(model2, modelnou)
AIC(model2, modelnou)
BIC(model2, modelnou)
anova(model2, modelnou)
zeromodel <- lm(accuracy ~ 1)
zeromodel <- lm(accuracy ~ 1, data = accuracy_df)
anova(zeromodel, model2, modelnou)
anova(model2, modelnou)
anova(zeromodel, model2, modelnou)
plot(modelnou)
shapiro.test(residuals(modelnou))
levene.test(residuals(modelnou))
leveneTest(residuals(modelnou))
View(accuracy_df)
leveneTest(modelnou)
barlett.test(modelnou)
gqtest(modelnou)
vif(modelnou)
#age of learning english model
engmodel <- lm(accuracy ~ age_english + condition, data = accuracy_df)
#age of learning english model
engmodel <- lm(accuracy ~ age_english + overall_cond, data = accuracy_df)
summary(engmodel)
engmodel2 <- lm(accuracy ~ overall_cond, data = accuracy_df)
summary(engmodel2)
nullengmodel <- lm(accuracy ~ 1)
nullengmodel <- lm(accuracy ~ 1, data = accuracy_df)
anova(zeromodel, engmodel)
#age of learning english model
engmodel <- lm(accuracy ~ age_english + overall_cond, data = accuracy_df)
anova(zeromodel,model2, engmodel)
#age of learning english model
plot(engmodel)
shapiro.test(residuals(engmodel))
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/pernillebrams/Desktop/AARHUS_UNIVERSITY/instructor_2024/methods-2")
# Make sure this guy is installed/updated (if you've alreadygot rstanarm installed, you just need to load it in using either library() or p_load() as below)
install.packages("rstanarm")
library(rstanarm)
# Load the rest
library(pacman)
pacman::p_load(tidyverse,
ggpubr,
ggplot2,
stringr) # this time I'm just giving you the code
# Load data
hibbs <- read.table("data/ElectionsEconomy/data/hibbs.dat", header = TRUE)
# Load data
hibbs <- read.table("data/ElectionsEconomy/data/hibbs.dat", header = TRUE)
getwd()
# Load data
hibbs <- read.table("data/ElectionsEconomy/data/hibbs.dat", header = TRUE)
knitr::opts_chunk$set(echo = TRUE)
# Setting my root directory to where I have my /data folder etc. (easier for me, but personalise to your own way of working)
knitr::opts_knit$set(root.dir = "/Users/pernillebrams/Desktop/AARHUS_UNIVERSITY/instructor_2024/methods-2")
# Load data
hibbs <- read.table("data/ElectionsEconomy/data/hibbs.dat", header = TRUE)
getwd()
setwd("C:/Users/chipe/OneDrive - Aarhus universitet/Dokumenter/methods02")
getwd()
setwd("C:/Users/chipe/OneDrive - Aarhus universitet/Dokumenter/methods02")
# Load data
hibbs <- read.table("data/ElectionsEconomy/data/hibbs.dat", header = TRUE)
setwd("C:/Users/chipe/OneDrive - Aarhus universitet/Dokumenter/methods02/classes")
# Load data
hibbs <- read.table("data/ElectionsEconomy/data/hibbs.dat", header = TRUE)
getwd()
getwd()
setwd("C:/Users/chipe/OneDrive - Aarhus universitet/Dokumenter/methods02")
setwd("C:/Users/chipe/OneDrive - Aarhus universitet/Dokumenter/methods02/classes")
# Load data
hibbs <- read.table("data/ElectionsEconomy/data/hibbs.dat", header = TRUE)
# Make scatterplot
plot(hibbs$growth, hibbs$vote, xlab="Average recent growth in personal income",
ylab="Incumbent party's vote share")
# Estimate regression y = a + bx + error
M1 <- stan_glm(vote ~ growth, data=hibbs)
# Make sure this guy is installed/updated (if you've alreadygot rstanarm installed, you just need to load it in using either library() or p_load() as below)
install.packages("rstanarm")
library(rstanarm)
# Load the rest
library(pacman)
pacman::p_load(tidyverse,
ggpubr,
ggplot2,
stringr) # this time I'm just giving you the code
View(hibbs)
setwd("C:/Users/chipe/OneDrive - Aarhus universitet/Dokumenter/methods02/classes")
# Load data
hibbs <- read.table("data/ElectionsEconomy/data/hibbs.dat", header = TRUE)
# Make scatterplot
plot(hibbs$growth, hibbs$vote, xlab="Average recent growth in personal income",
ylab="Incumbent party's vote share")
# Estimate regression y = a + bx + error
M1 <- stan_glm(vote ~ growth, data=hibbs)
# Add a fitted line to the graph
abline(coef(M1), col="gray") # needs to be run with the plot() code above - running the whole chunk is the easiest way
# Display the fitted model
print(M1)
# Basic plot with ggplot2
ggplot(hibbs, aes(x = growth, y = vote)) +
geom_point() +  # Add points
labs(
x = "Average recent growth in personal income",
y = "Incumbent party's vote share",
title = "Relationship between Income Growth and Vote Share",
subtitle = "Data from Hibbs Dataset"
) +
theme_minimal() +  # Use a minimal theme
theme(
plot.title = element_text(hjust = 0.5),  # Center the title
plot.subtitle = element_text(hjust = 0.5)  # Center the subtitle
) +
geom_smooth(method = "lm", se = FALSE, color = "blue")  # Add a linear regression line
rnorm(30, mean = 0, sd = 1)
set.seed(1998) # setting a seed (in the best year ever??) - this way, even though it's random, you'll get reproducible results next time you run this with this seed
# rnorm() works like: my_simulated_data <- rnorm(n, mean, sd) - now you go!
# your code here
my_simulated_data <- rnorm(100, 3, 5) - now you go!
set.seed(1998) # setting a seed (in the best year ever??) - this way, even though it's random, you'll get reproducible results next time you run this with this seed
# rnorm() works like: my_simulated_data <- rnorm(n, mean, sd) - now you go!
# your code here
my_simulated_data <- rnorm(100, 3, 5)
my_simulated_data
ggplot(data=my_simulated_data)
ggplot(data=my_simulated_data)+
geom_histogram()
